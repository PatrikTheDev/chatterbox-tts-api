version: '3.8'

services:
  # Main API Service (always included)
  chatterbox-tts:
    profiles: ['single', 'fullstack']
    build:
      dockerfile: Dockerfile.uv.gpu
    container_name: chatterbox-tts-api-uv-gpu
    ports:
      - '${PORT:-4123}:${PORT:-4123}'
    environment:
      # API Configuration
      - PORT=${PORT:-4123}
      - HOST=${HOST:-0.0.0.0}

      # TTS Model Settings
      - EXAGGERATION=${EXAGGERATION:-0.5}
      - CFG_WEIGHT=${CFG_WEIGHT:-0.5}
      - TEMPERATURE=${TEMPERATURE:-0.8}

      # Text Processing
      - MAX_CHUNK_LENGTH=${MAX_CHUNK_LENGTH:-280}
      - MAX_TOTAL_LENGTH=${MAX_TOTAL_LENGTH:-3000}

      # Voice and Model Settings
      - VOICE_SAMPLE_PATH=/app/voice-sample.mp3
      - DEVICE=${DEVICE:-cuda}
      - MODEL_CACHE_DIR=${MODEL_CACHE_DIR:-/cache}
      - VOICE_LIBRARY_DIR=${VOICE_LIBRARY_DIR:-/voices}

      # NVIDIA/CUDA settings
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - chatterbox-models:/cache
      - chatterbox-voices:/voices

    # GPU support (enabled by default for this compose file)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    restart: unless-stopped

    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:$${PORT:-4123}/ping || curl -fsS http://localhost:$${PORT:-4123}/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 300s

  # Frontend Service with integrated proxy (optional - requires 'frontend' profile)
  frontend:
    profiles: ['frontend', 'ui', 'fullstack']
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: chatterbox-tts-frontend
    ports:
      - '${FRONTEND_PORT:-4321}:80' # Frontend serves on port 80 internally
    depends_on:
      - chatterbox-tts
    restart: unless-stopped

  frontend-gpu0:
    profiles: ['gpu4']
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: chatterbox-tts-frontend-0
    ports:
      - '4321:80'
    depends_on:
      - chatterbox-tts-gpu0
    links:
      - chatterbox-tts-gpu0:chatterbox-tts
    restart: unless-stopped

  frontend-gpu1:
    profiles: ['gpu4']
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: chatterbox-tts-frontend-1
    ports:
      - '4322:80'
    depends_on:
      - chatterbox-tts-gpu1
    links:
      - chatterbox-tts-gpu1:chatterbox-tts
    restart: unless-stopped

  frontend-gpu2:
    profiles: ['gpu4']
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: chatterbox-tts-frontend-2
    ports:
      - '4323:80'
    depends_on:
      - chatterbox-tts-gpu2
    links:
      - chatterbox-tts-gpu2:chatterbox-tts
    restart: unless-stopped

  frontend-gpu3:
    profiles: ['gpu4']
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: chatterbox-tts-frontend-3
    ports:
      - '4324:80'
    depends_on:
      - chatterbox-tts-gpu3
    links:
      - chatterbox-tts-gpu3:chatterbox-tts
    restart: unless-stopped

  # 4Ã—GPU profile: four API instances pinned to GPU 0..3
  chatterbox-tts-gpu0:
    profiles: ['gpu4']
    build:
      dockerfile: Dockerfile.uv.gpu
    container_name: chatterbox-tts-api-uv-gpu-0
    ports:
      - '4124:4123'
    environment:
      # API Configuration
      - PORT=4123
      - HOST=0.0.0.0

      # TTS Model Settings
      - EXAGGERATION=${EXAGGERATION:-0.5}
      - CFG_WEIGHT=${CFG_WEIGHT:-0.5}
      - TEMPERATURE=${TEMPERATURE:-0.8}

      # Text Processing
      - MAX_CHUNK_LENGTH=${MAX_CHUNK_LENGTH:-280}
      - MAX_TOTAL_LENGTH=${MAX_TOTAL_LENGTH:-3000}

      # Voice and Model Settings
      - VOICE_SAMPLE_PATH=/app/voice-sample.mp3
      - DEVICE=${DEVICE:-cuda}
      - MODEL_CACHE_DIR=${MODEL_CACHE_DIR:-/cache}
      - VOICE_LIBRARY_DIR=${VOICE_LIBRARY_DIR:-/voices}

      # NVIDIA/CUDA settings (do not set NVIDIA_VISIBLE_DEVICES here; device reservation below will scope visibility)
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - chatterbox-models:/cache
      - chatterbox-voices:/voices

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]

    restart: unless-stopped

    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:4123/ping || curl -fsS http://localhost:4123/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 300s

  chatterbox-tts-gpu1:
    profiles: ['gpu4']
    build:
      dockerfile: Dockerfile.uv.gpu
    container_name: chatterbox-tts-api-uv-gpu-1
    ports:
      - '4125:4123'
    environment:
      - PORT=4123
      - HOST=0.0.0.0
      - EXAGGERATION=${EXAGGERATION:-0.5}
      - CFG_WEIGHT=${CFG_WEIGHT:-0.5}
      - TEMPERATURE=${TEMPERATURE:-0.8}
      - MAX_CHUNK_LENGTH=${MAX_CHUNK_LENGTH:-280}
      - MAX_TOTAL_LENGTH=${MAX_TOTAL_LENGTH:-3000}
      - VOICE_SAMPLE_PATH=/app/voice-sample.mp3
      - DEVICE=${DEVICE:-cuda}
      - MODEL_CACHE_DIR=${MODEL_CACHE_DIR:-/cache}
      - VOICE_LIBRARY_DIR=${VOICE_LIBRARY_DIR:-/voices}
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - chatterbox-models:/cache
      - chatterbox-voices:/voices
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["1"]
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:4123/ping || curl -fsS http://localhost:4123/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 300s

  chatterbox-tts-gpu2:
    profiles: ['gpu4']
    build:
      dockerfile: Dockerfile.uv.gpu
    container_name: chatterbox-tts-api-uv-gpu-2
    ports:
      - '4126:4123'
    environment:
      - PORT=4123
      - HOST=0.0.0.0
      - EXAGGERATION=${EXAGGERATION:-0.5}
      - CFG_WEIGHT=${CFG_WEIGHT:-0.5}
      - TEMPERATURE=${TEMPERATURE:-0.8}
      - MAX_CHUNK_LENGTH=${MAX_CHUNK_LENGTH:-280}
      - MAX_TOTAL_LENGTH=${MAX_TOTAL_LENGTH:-3000}
      - VOICE_SAMPLE_PATH=/app/voice-sample.mp3
      - DEVICE=${DEVICE:-cuda}
      - MODEL_CACHE_DIR=${MODEL_CACHE_DIR:-/cache}
      - VOICE_LIBRARY_DIR=${VOICE_LIBRARY_DIR:-/voices}
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - chatterbox-models:/cache
      - chatterbox-voices:/voices
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["2"]
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:4123/ping || curl -fsS http://localhost:4123/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 300s

  chatterbox-tts-gpu3:
    profiles: ['gpu4']
    build:
      dockerfile: Dockerfile.uv.gpu
    container_name: chatterbox-tts-api-uv-gpu-3
    ports:
      - '4127:4123'
    environment:
      - PORT=4123
      - HOST=0.0.0.0
      - EXAGGERATION=${EXAGGERATION:-0.5}
      - CFG_WEIGHT=${CFG_WEIGHT:-0.5}
      - TEMPERATURE=${TEMPERATURE:-0.8}
      - MAX_CHUNK_LENGTH=${MAX_CHUNK_LENGTH:-280}
      - MAX_TOTAL_LENGTH=${MAX_TOTAL_LENGTH:-3000}
      - VOICE_SAMPLE_PATH=/app/voice-sample.mp3
      - DEVICE=${DEVICE:-cuda}
      - MODEL_CACHE_DIR=${MODEL_CACHE_DIR:-/cache}
      - VOICE_LIBRARY_DIR=${VOICE_LIBRARY_DIR:-/voices}
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - chatterbox-models:/cache
      - chatterbox-voices:/voices
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["3"]
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:4123/ping || curl -fsS http://localhost:4123/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 300s

volumes:
  chatterbox-models:
    driver: local
  chatterbox-voices:
    driver: local
