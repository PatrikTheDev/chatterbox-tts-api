version: '3.8'

services:
  # Main API Service (always included)
  chatterbox-tts:
    build:
      dockerfile: Dockerfile.uv.gpu
    container_name: chatterbox-tts-api-uv-gpu
    ports:
      - '${PORT:-4123}:${PORT:-4123}'
    environment:
      # API Configuration
      - PORT=${PORT:-4123}
      - HOST=${HOST:-0.0.0.0}

      # TTS Model Settings
      - EXAGGERATION=${EXAGGERATION:-0.5}
      - CFG_WEIGHT=${CFG_WEIGHT:-0.5}
      - TEMPERATURE=${TEMPERATURE:-0.8}

      # Text Processing
      - MAX_CHUNK_LENGTH=${MAX_CHUNK_LENGTH:-280}
      - MAX_TOTAL_LENGTH=${MAX_TOTAL_LENGTH:-3000}

      # Voice and Model Settings
      - VOICE_SAMPLE_PATH=/app/voice-sample.mp3
      - DEVICE=${DEVICE:-cuda}
      - MODEL_CACHE_DIR=${MODEL_CACHE_DIR:-/cache}
      - VOICE_LIBRARY_DIR=${VOICE_LIBRARY_DIR:-/voices}

      # Memory Settings
      - MEMORY_CLEANUP_INTERVAL=${MEMORY_CLEANUP_INTERVAL:-32}

      # NVIDIA/CUDA settings
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - chatterbox-models:/cache
      - chatterbox-voices:/voices

    # GPU support (enabled by default for this compose file)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    restart: unless-stopped

    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:${PORT:-4123}/health']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 300s

  # Frontend Service with integrated proxy (optional - requires 'frontend' profile)
  frontend:
    profiles: ['frontend', 'ui', 'fullstack']
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: chatterbox-tts-frontend
    ports:
      - '${FRONTEND_PORT:-4321}:80' # Frontend serves on port 80 internally
    depends_on:
      - chatterbox-tts
    restart: unless-stopped

volumes:
  chatterbox-models:
    driver: local
  chatterbox-voices:
    driver: local
